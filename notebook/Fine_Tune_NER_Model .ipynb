{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yibabe\\Desktop\\10academyAIMweek-5\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Yibabe\\Desktop\\10academyAIMweek-5\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "model_name = \"xlm-roberta-base\"  # You can also use bert-tiny-amharic if available\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=5)  # Adjust num_labels based on your entity types (e.g., products, prices, locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset with `trust_remote_code=True`\n",
    "dataset = load_dataset(\"conll2003\", split=\"train\", trust_remote_code=True)\n",
    "\n",
    "# Check the first few rows to ensure it's loaded correctly\n",
    "print(dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yibabe\\Desktop\\10academyAIMweek-5\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the XLM-Roberta tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the entire data from the CSV file\n",
    "data_file_path = r'C:\\Users\\Yibabe\\Desktop\\10academyAIMweek-5\\data\\cleaned_tokenized_and_labled_data.csv' \n",
    "df = pd.read_csv(data_file_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labeled_Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GW O\\nHAIR O\\nDRYER/Blower O\\nየፀጉር O\\nማድረቂያ O\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 B-PRODUCT\\nin I-PRODUCT\\n1 I-PRODUCT\\nPorcel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plastic B-PRODUCT\\nAnd I-PRODUCT\\nMetal I-PROD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Labeled_Message\n",
       "0  Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...\n",
       "1  Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...\n",
       "2  GW O\\nHAIR O\\nDRYER/Blower O\\nየፀጉር O\\nማድረቂያ O\\...\n",
       "3  2 B-PRODUCT\\nin I-PRODUCT\\n1 I-PRODUCT\\nPorcel...\n",
       "4  Plastic B-PRODUCT\\nAnd I-PRODUCT\\nMetal I-PROD..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming the relevant text column is named 'Labeled_Message'; adjust this if needed\n",
    "if 'Labeled_Message' not in df.columns:\n",
    "    raise ValueError(\"The 'Labeled_Message' column is not found in the DataFrame.\")\n",
    "\n",
    "# Redundant messages to be removed\n",
    "redundant_message = [\n",
    "    \"ከፍለው O\",\n",
    "    \"ካሉበት O\",\n",
    "    \"እንልካለን O\",\n",
    "    \"ክፍለሃገር O\",\n",
    "    \"ላላችሁ O\",\n",
    "    \"ደንበኞቻችን O\",\n",
    "    \"የፈለጉትን O\",\n",
    "    \"ዕቃ O\",\n",
    "    \"በመልዕክት O\",\n",
    "    \"እንልክልዎታለን O\",\n",
    "    \"ለማዘዝ O\",\n",
    "    \"@ordermertteka1 O\",\n",
    "    \"@ordermertteka2 O\",\n",
    "    \"ለወዳጅዎ O\",\n",
    "    \"forward O\",\n",
    "    \"በማድረግ O\",\n",
    "    \"ይተባበሩን O\",\n",
    "    \"0944-22-23-24 O\",\n",
    "    \"0904-94-48-48 O\",\n",
    "    \"አድራሻችን O\",\n",
    "    \"መገናኛ I-LOC\",\n",
    "    \"ዘፍመሽ O\",\n",
    "    \"ግራንድ O\",\n",
    "    \"ሞል O\",\n",
    "    \"3ኛ O\",\n",
    "    \"ፎቅ O\",\n",
    "    \"ከሊፍት O\",\n",
    "    \"ሲወርዱ O\",\n",
    "    \"ወደ O\",\n",
    "    \"ቀኝ O\",\n",
    "    \"ታጥፈው O\",\n",
    "    \"ቀጥታ O\",\n",
    "    \"376 I-LOC\",\n",
    "    \"በኪስዎ O\",\n",
    "    \"ጥሬ O\",\n",
    "    \"ገንዘብ O\",\n",
    "    \"ካልያዙ O\",\n",
    "    \"በሞባይል O\",\n",
    "    \"ማስተላለፍ O\",\n",
    "    \"ይችላሉ። O\",\n",
    "    \"ይሄንን O\",\n",
    "    \"t.me/MerttEka O\",\n",
    "    \"ተጭነው O\",\n",
    "    \"join O\",\n",
    "    \"ያድርጉ፣ O\",\n",
    "    \"ቤተሰብ O\",\n",
    "    \"ይሁኑ O\"\n",
    "]\n",
    "\n",
    "# Function to clean redundant messages\n",
    "def clean_redundant_messages(text):\n",
    "    # Check if the text is a string\n",
    "    if isinstance(text, str):\n",
    "        for message in set(redundant_message):\n",
    "            text = text.replace(message + \"\\n\", \"\")\n",
    "        return text.strip()  # Remove leading/trailing whitespace after replacement\n",
    "    return None  # Return None for non-string entries\n",
    "\n",
    "# Clean the redundant messages in the DataFrame\n",
    "df['cleaned_text'] = df['Labeled_Message'].apply(clean_redundant_messages)\n",
    "\n",
    "# Function to split tokens and labels\n",
    "def split_tokens_and_labels(text):\n",
    "    if isinstance(text, str):  # Ensure the input is a string\n",
    "        lines = text.strip().split('\\n')\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for line in lines:\n",
    "            if line.strip():  # Ensure the line is not empty\n",
    "                token, label = line.rsplit(' ', 1)\n",
    "                tokens.append(token)\n",
    "                labels.append(label)\n",
    "        return tokens, labels\n",
    "    else:\n",
    "        return [], []  # Return empty lists for non-string entries\n",
    "\n",
    "# Apply the token splitting\n",
    "df['tokens_labels'] = df['cleaned_text'].apply(split_tokens_and_labels)\n",
    "\n",
    "# Separate tokens and labels into two new columns\n",
    "df['tokens'] = df['tokens_labels'].apply(lambda x: x[0])\n",
    "df['labels'] = df['tokens_labels'].apply(lambda x: x[1])\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "# output_file_path = r'C:\\Users\\Yibabe\\Desktop\\10academyAIMweek-5\\data\\cleaned_data.csv' # Update this to your desired output path\n",
    "# df.to_csv(output_file_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...</td>\n",
       "      <td>[Car, Aromatherapy, Solar, Vortex, ይሁኑ]</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...</td>\n",
       "      <td>[Car, Aromatherapy, Solar, Vortex, የመኪና, መዓዛ, ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GW O\\nHAIR O\\nDRYER/Blower O\\nየፀጉር O\\nማድረቂያ O\\...</td>\n",
       "      <td>[GW, HAIR, DRYER/Blower, የፀጉር, ማድረቂያ, ፎን, 6000...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 B-PRODUCT\\nin I-PRODUCT\\n1 I-PRODUCT\\nPorcel...</td>\n",
       "      <td>[2, in, 1, Porcelain, Dessert, Bowel, የሰላጣ, እና...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plastic B-PRODUCT\\nAnd I-PRODUCT\\nMetal I-PROD...</td>\n",
       "      <td>[Plastic, And, Metal, Cubic, Cloth, Cabinet, ዘ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>2500 B-PRODUCT</td>\n",
       "      <td>[2500]</td>\n",
       "      <td>[B-PRODUCT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>ዋጋ B-PRODUCT\\n2500 I-PRODUCT\\n0983063957 O</td>\n",
       "      <td>[ዋጋ, 2500, 0983063957]</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>የሙያ B-PRODUCT\\nባለቤት I-PRODUCT\\nመሆን I-PRODUCT\\n...</td>\n",
       "      <td>[የሙያ, ባለቤት, መሆን, መሠልጠን, ነው።, ቀለም, ቀቢ, ሳያስፈልግዎ,...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>ቤትና B-PRODUCT\\nግቢዎን I-PRODUCT\\nእንዲሁም I-PRODUCT...</td>\n",
       "      <td>[ቤትና, ግቢዎን, እንዲሁም, የብረት, እና, የእንጨት, ቁሳቁስዎን, ቀለ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>ለማዘዝ B-PRODUCT\\nhttps://t.megojomewechiyaeka O</td>\n",
       "      <td>[ለማዘዝ, https://t.megojomewechiyaeka]</td>\n",
       "      <td>[B-PRODUCT, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4083 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_text  \\\n",
       "0     Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...   \n",
       "1     Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...   \n",
       "2     GW O\\nHAIR O\\nDRYER/Blower O\\nየፀጉር O\\nማድረቂያ O\\...   \n",
       "3     2 B-PRODUCT\\nin I-PRODUCT\\n1 I-PRODUCT\\nPorcel...   \n",
       "4     Plastic B-PRODUCT\\nAnd I-PRODUCT\\nMetal I-PROD...   \n",
       "...                                                 ...   \n",
       "4078                                     2500 B-PRODUCT   \n",
       "4079         ዋጋ B-PRODUCT\\n2500 I-PRODUCT\\n0983063957 O   \n",
       "4080  የሙያ B-PRODUCT\\nባለቤት I-PRODUCT\\nመሆን I-PRODUCT\\n...   \n",
       "4081  ቤትና B-PRODUCT\\nግቢዎን I-PRODUCT\\nእንዲሁም I-PRODUCT...   \n",
       "4082     ለማዘዝ B-PRODUCT\\nhttps://t.megojomewechiyaeka O   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0               [Car, Aromatherapy, Solar, Vortex, ይሁኑ]   \n",
       "1     [Car, Aromatherapy, Solar, Vortex, የመኪና, መዓዛ, ...   \n",
       "2     [GW, HAIR, DRYER/Blower, የፀጉር, ማድረቂያ, ፎን, 6000...   \n",
       "3     [2, in, 1, Porcelain, Dessert, Bowel, የሰላጣ, እና...   \n",
       "4     [Plastic, And, Metal, Cubic, Cloth, Cabinet, ዘ...   \n",
       "...                                                 ...   \n",
       "4078                                             [2500]   \n",
       "4079                             [ዋጋ, 2500, 0983063957]   \n",
       "4080  [የሙያ, ባለቤት, መሆን, መሠልጠን, ነው።, ቀለም, ቀቢ, ሳያስፈልግዎ,...   \n",
       "4081  [ቤትና, ግቢዎን, እንዲሁም, የብረት, እና, የእንጨት, ቁሳቁስዎን, ቀለ...   \n",
       "4082               [ለማዘዝ, https://t.megojomewechiyaeka]   \n",
       "\n",
       "                                                 labels  \n",
       "0       [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O]  \n",
       "1     [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O...  \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3     [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  \n",
       "4     [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  \n",
       "...                                                 ...  \n",
       "4078                                        [B-PRODUCT]  \n",
       "4079                          [B-PRODUCT, I-PRODUCT, O]  \n",
       "4080  [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  \n",
       "4081  [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  \n",
       "4082                                     [B-PRODUCT, O]  \n",
       "\n",
       "[4083 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the resulting DataFrame (optional)\n",
    "df[['cleaned_text', 'tokens', 'labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              [Car, Aromatherapy, Solar, Vortex, ይሁኑ]\n",
       "1    [Car, Aromatherapy, Solar, Vortex, የመኪና, መዓዛ, ...\n",
       "2    [GW, HAIR, DRYER/Blower, የፀጉር, ማድረቂያ, ፎን, 6000...\n",
       "3    [2, in, 1, Porcelain, Dessert, Bowel, የሰላጣ, እና...\n",
       "4    [Plastic, And, Metal, Cubic, Cloth, Cabinet, ዘ...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O]\n",
       "1    [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O...\n",
       "2    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...\n",
       "3    [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...\n",
       "4    [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...\n",
       "Name: labels, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to split cleaned text into tokens and labels\n",
    "def split_tokens_labels(row):\n",
    "    cleaned_text = row['cleaned_text']\n",
    "    \n",
    "    # Check if cleaned_text is None or an empty string\n",
    "    if cleaned_text is None or cleaned_text.strip() == \"\":\n",
    "        return ([], []), [], []  # Return empty lists if cleaned_text is not valid\n",
    "    \n",
    "    # Split the cleaned text into lines\n",
    "    lines = cleaned_text.strip().split('\\n')\n",
    "    \n",
    "    # Initialize lists for tokens and labels\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate through each line\n",
    "    for line in lines:\n",
    "        # Split each line by space\n",
    "        parts = line.rsplit(' ', 1)  # Split only at the last space\n",
    "        if len(parts) == 2:  # Ensure there's a token and a label\n",
    "            token, label = parts\n",
    "            tokens.append(token)\n",
    "            labels.append(label)\n",
    "    \n",
    "    # Create tokens_labels format as a tuple of lists\n",
    "    tokens_labels = (tokens, labels)\n",
    "    \n",
    "    return tokens_labels, tokens, labels\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df[['tokens_labels', 'tokens', 'labels']] = df.apply(split_tokens_labels, axis=1, result_type='expand')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens_labels</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...</td>\n",
       "      <td>([Car, Aromatherapy, Solar, Vortex, ይሁኑ], [B-P...</td>\n",
       "      <td>[Car, Aromatherapy, Solar, Vortex, ይሁኑ]</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...</td>\n",
       "      <td>([Car, Aromatherapy, Solar, Vortex, የመኪና, መዓዛ,...</td>\n",
       "      <td>[Car, Aromatherapy, Solar, Vortex, የመኪና, መዓዛ, ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GW O\\nHAIR O\\nDRYER/Blower O\\nየፀጉር O\\nማድረቂያ O\\...</td>\n",
       "      <td>([GW, HAIR, DRYER/Blower, የፀጉር, ማድረቂያ, ፎን, 600...</td>\n",
       "      <td>[GW, HAIR, DRYER/Blower, የፀጉር, ማድረቂያ, ፎን, 6000...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 B-PRODUCT\\nin I-PRODUCT\\n1 I-PRODUCT\\nPorcel...</td>\n",
       "      <td>([2, in, 1, Porcelain, Dessert, Bowel, የሰላጣ, እ...</td>\n",
       "      <td>[2, in, 1, Porcelain, Dessert, Bowel, የሰላጣ, እና...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plastic B-PRODUCT\\nAnd I-PRODUCT\\nMetal I-PROD...</td>\n",
       "      <td>([Plastic, And, Metal, Cubic, Cloth, Cabinet, ...</td>\n",
       "      <td>[Plastic, And, Metal, Cubic, Cloth, Cabinet, ዘ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text  \\\n",
       "0  Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...   \n",
       "1  Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...   \n",
       "2  GW O\\nHAIR O\\nDRYER/Blower O\\nየፀጉር O\\nማድረቂያ O\\...   \n",
       "3  2 B-PRODUCT\\nin I-PRODUCT\\n1 I-PRODUCT\\nPorcel...   \n",
       "4  Plastic B-PRODUCT\\nAnd I-PRODUCT\\nMetal I-PROD...   \n",
       "\n",
       "                                       tokens_labels  \\\n",
       "0  ([Car, Aromatherapy, Solar, Vortex, ይሁኑ], [B-P...   \n",
       "1  ([Car, Aromatherapy, Solar, Vortex, የመኪና, መዓዛ,...   \n",
       "2  ([GW, HAIR, DRYER/Blower, የፀጉር, ማድረቂያ, ፎን, 600...   \n",
       "3  ([2, in, 1, Porcelain, Dessert, Bowel, የሰላጣ, እ...   \n",
       "4  ([Plastic, And, Metal, Cubic, Cloth, Cabinet, ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0            [Car, Aromatherapy, Solar, Vortex, ይሁኑ]   \n",
       "1  [Car, Aromatherapy, Solar, Vortex, የመኪና, መዓዛ, ...   \n",
       "2  [GW, HAIR, DRYER/Blower, የፀጉር, ማድረቂያ, ፎን, 6000...   \n",
       "3  [2, in, 1, Porcelain, Dessert, Bowel, የሰላጣ, እና...   \n",
       "4  [Plastic, And, Metal, Cubic, Cloth, Cabinet, ዘ...   \n",
       "\n",
       "                                              labels  \n",
       "0    [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O]  \n",
       "1  [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  \n",
       "4  [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Display the updated DataFrame\n",
    "df[['cleaned_text', 'tokens_labels', 'tokens', 'labels']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset for training\n",
    "train_data = [(row['tokens'], row['labels']) for _, row in df.iterrows() if row['tokens'] and row['labels']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word in the original sentence\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yibabe\\Desktop\\10academyAIMweek-5\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    # Tokenize the tokens column\n",
    "    tokenized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    # Create empty labels list\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Get the word IDs after tokenization\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                # If there is no word ID, append a label for special tokens (CLS, SEP, etc.)\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # Label for the first sub-token of a word\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                # Label for the subsequent sub-tokens of a word\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    # Add the labels to the tokenized inputs\n",
    "    tokenized_inputs['labels'] = labels\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the tokenization and label alignment\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerateNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (4.45.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers[torch]) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers[torch]) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers[torch]) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers[torch]) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: torch in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers[torch]) (2.4.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from torch->transformers[torch]) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from torch->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from torch->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from torch->transformers[torch]) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from requests->transformers[torch]) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Downloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.34.2\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch] accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 3674\n",
      "Validation dataset size: 409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "# Assuming df1 is your DataFrame containing the tokenized data\n",
    "train_df, val_df = train_test_split(df1, test_size=0.1, random_state=42)  # 10% for validation\n",
    "\n",
    "# Convert DataFrames to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "# Check the datasets\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labeled_Message</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens_labels</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>ታጣፊ B-PRODUCT\\nየመስክ I-PRODUCT\\nአልጋ። I-PRODUCT\\...</td>\n",
       "      <td>ታጣፊ B-PRODUCT\\nየመስክ I-PRODUCT\\nአልጋ። I-PRODUCT\\...</td>\n",
       "      <td>([ታጣፊ, የመስክ, አልጋ።, ከጠንካራ, ሸራ, እና, ከጠንካራ, አልሙኒየ...</td>\n",
       "      <td>[ታጣፊ, የመስክ, አልጋ።, ከጠንካራ, ሸራ, እና, ከጠንካራ, አልሙኒየም...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>ProLISS B-PRODUCT\\nDEEP I-PRODUCT\\nOIL I-PRODU...</td>\n",
       "      <td>ProLISS B-PRODUCT\\nDEEP I-PRODUCT\\nOIL I-PRODU...</td>\n",
       "      <td>([ProLISS, DEEP, OIL, FRYER, አሳንቡሳ፣, ቺብስ፣, ዓሳ፣...</td>\n",
       "      <td>[ProLISS, DEEP, OIL, FRYER, አሳንቡሳ፣, ቺብስ፣, ዓሳ፣,...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>mini B-PRODUCT\\nwashing I-PRODUCT\\nmachine I-P...</td>\n",
       "      <td>mini B-PRODUCT\\nwashing I-PRODUCT\\nmachine I-P...</td>\n",
       "      <td>([mini, washing, machine], [B-PRODUCT, I-PRODU...</td>\n",
       "      <td>[mini, washing, machine]</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>ሶስተኛው B-PRODUCT\\nስጦታ I-PRODUCT</td>\n",
       "      <td>ሶስተኛው B-PRODUCT\\nስጦታ I-PRODUCT</td>\n",
       "      <td>([ሶስተኛው, ስጦታ], [B-PRODUCT, I-PRODUCT])</td>\n",
       "      <td>[ሶስተኛው, ስጦታ]</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>Hand B-PRODUCT\\nmixer I-PRODUCT\\nwith I-PRODUC...</td>\n",
       "      <td>Hand B-PRODUCT\\nmixer I-PRODUCT\\nwith I-PRODUC...</td>\n",
       "      <td>([Hand, mixer, with, 3, cake, molds, 2100, ብር,...</td>\n",
       "      <td>[Hand, mixer, with, 3, cake, molds, 2100, ብር, ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>Silcon B-PRODUCT\\nShower I-PRODUCT\\nBrush I-PR...</td>\n",
       "      <td>Silcon B-PRODUCT\\nShower I-PRODUCT\\nBrush I-PR...</td>\n",
       "      <td>([Silcon, Shower, Brush, ፈሳሽ, ሳሙና, ማስቀመጫ, አለው,...</td>\n",
       "      <td>[Silcon, Shower, Brush, ፈሳሽ, ሳሙና, ማስቀመጫ, አለው, ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>Wass B-PRODUCT\\nMitad I-PRODUCT\\nዋስ O\\nምጣድ O\\n...</td>\n",
       "      <td>Wass B-PRODUCT\\nMitad I-PRODUCT\\nዋስ O\\nምጣድ O\\n...</td>\n",
       "      <td>([Wass, Mitad, ዋስ, ምጣድ, 16, inch(41, cm), ስፋት,...</td>\n",
       "      <td>[Wass, Mitad, ዋስ, ምጣድ, 16, inch(41, cm), ስፋት, ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, O, O, I-PRICE, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Flat B-PRODUCT\\nMop I-PRODUCT\\nSet I-PRODUCT\\n...</td>\n",
       "      <td>Flat B-PRODUCT\\nMop I-PRODUCT\\nSet I-PRODUCT\\n...</td>\n",
       "      <td>([Flat, Mop, Set, የወለልና, የመስታወት, መወልወያ, ትልቁ, መ...</td>\n",
       "      <td>[Flat, Mop, Set, የወለልና, የመስታወት, መወልወያ, ትልቁ, መጠ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>Serving B-PRODUCT\\ntray I-PRODUCT\\nለዳቦ O\\nለእንጀ...</td>\n",
       "      <td>Serving B-PRODUCT\\ntray I-PRODUCT\\nለዳቦ O\\nለእንጀ...</td>\n",
       "      <td>([Serving, tray, ለዳቦ, ለእንጀራ, ለፈንዲሻ, እና, ሌሎች, ም...</td>\n",
       "      <td>[Serving, tray, ለዳቦ, ለእንጀራ, ለፈንዲሻ, እና, ሌሎች, ምግ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, O, O, O, O, O, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>GW B-PRODUCT\\n3 I-PRODUCT\\nin I-PRODUCT\\n1 I-P...</td>\n",
       "      <td>GW B-PRODUCT\\n3 I-PRODUCT\\nin I-PRODUCT\\n1 I-P...</td>\n",
       "      <td>([GW, 3, in, 1, hot, air, Hair, styler, የሚዘንጡ,...</td>\n",
       "      <td>[GW, 3, in, 1, hot, air, Hair, styler, የሚዘንጡ, ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3674 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Labeled_Message  \\\n",
       "3867  ታጣፊ B-PRODUCT\\nየመስክ I-PRODUCT\\nአልጋ። I-PRODUCT\\...   \n",
       "810   ProLISS B-PRODUCT\\nDEEP I-PRODUCT\\nOIL I-PRODU...   \n",
       "2506  mini B-PRODUCT\\nwashing I-PRODUCT\\nmachine I-P...   \n",
       "3653                     ሶስተኛው B-PRODUCT\\nስጦታ I-PRODUCT   \n",
       "3468  Hand B-PRODUCT\\nmixer I-PRODUCT\\nwith I-PRODUC...   \n",
       "...                                                 ...   \n",
       "1130  Silcon B-PRODUCT\\nShower I-PRODUCT\\nBrush I-PR...   \n",
       "1294  Wass B-PRODUCT\\nMitad I-PRODUCT\\nዋስ O\\nምጣድ O\\n...   \n",
       "860   Flat B-PRODUCT\\nMop I-PRODUCT\\nSet I-PRODUCT\\n...   \n",
       "3507  Serving B-PRODUCT\\ntray I-PRODUCT\\nለዳቦ O\\nለእንጀ...   \n",
       "3174  GW B-PRODUCT\\n3 I-PRODUCT\\nin I-PRODUCT\\n1 I-P...   \n",
       "\n",
       "                                           cleaned_text  \\\n",
       "3867  ታጣፊ B-PRODUCT\\nየመስክ I-PRODUCT\\nአልጋ። I-PRODUCT\\...   \n",
       "810   ProLISS B-PRODUCT\\nDEEP I-PRODUCT\\nOIL I-PRODU...   \n",
       "2506  mini B-PRODUCT\\nwashing I-PRODUCT\\nmachine I-P...   \n",
       "3653                     ሶስተኛው B-PRODUCT\\nስጦታ I-PRODUCT   \n",
       "3468  Hand B-PRODUCT\\nmixer I-PRODUCT\\nwith I-PRODUC...   \n",
       "...                                                 ...   \n",
       "1130  Silcon B-PRODUCT\\nShower I-PRODUCT\\nBrush I-PR...   \n",
       "1294  Wass B-PRODUCT\\nMitad I-PRODUCT\\nዋስ O\\nምጣድ O\\n...   \n",
       "860   Flat B-PRODUCT\\nMop I-PRODUCT\\nSet I-PRODUCT\\n...   \n",
       "3507  Serving B-PRODUCT\\ntray I-PRODUCT\\nለዳቦ O\\nለእንጀ...   \n",
       "3174  GW B-PRODUCT\\n3 I-PRODUCT\\nin I-PRODUCT\\n1 I-P...   \n",
       "\n",
       "                                          tokens_labels  \\\n",
       "3867  ([ታጣፊ, የመስክ, አልጋ።, ከጠንካራ, ሸራ, እና, ከጠንካራ, አልሙኒየ...   \n",
       "810   ([ProLISS, DEEP, OIL, FRYER, አሳንቡሳ፣, ቺብስ፣, ዓሳ፣...   \n",
       "2506  ([mini, washing, machine], [B-PRODUCT, I-PRODU...   \n",
       "3653             ([ሶስተኛው, ስጦታ], [B-PRODUCT, I-PRODUCT])   \n",
       "3468  ([Hand, mixer, with, 3, cake, molds, 2100, ብር,...   \n",
       "...                                                 ...   \n",
       "1130  ([Silcon, Shower, Brush, ፈሳሽ, ሳሙና, ማስቀመጫ, አለው,...   \n",
       "1294  ([Wass, Mitad, ዋስ, ምጣድ, 16, inch(41, cm), ስፋት,...   \n",
       "860   ([Flat, Mop, Set, የወለልና, የመስታወት, መወልወያ, ትልቁ, መ...   \n",
       "3507  ([Serving, tray, ለዳቦ, ለእንጀራ, ለፈንዲሻ, እና, ሌሎች, ም...   \n",
       "3174  ([GW, 3, in, 1, hot, air, Hair, styler, የሚዘንጡ,...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "3867  [ታጣፊ, የመስክ, አልጋ።, ከጠንካራ, ሸራ, እና, ከጠንካራ, አልሙኒየም...   \n",
       "810   [ProLISS, DEEP, OIL, FRYER, አሳንቡሳ፣, ቺብስ፣, ዓሳ፣,...   \n",
       "2506                           [mini, washing, machine]   \n",
       "3653                                       [ሶስተኛው, ስጦታ]   \n",
       "3468  [Hand, mixer, with, 3, cake, molds, 2100, ብር, ...   \n",
       "...                                                 ...   \n",
       "1130  [Silcon, Shower, Brush, ፈሳሽ, ሳሙና, ማስቀመጫ, አለው, ...   \n",
       "1294  [Wass, Mitad, ዋስ, ምጣድ, 16, inch(41, cm), ስፋት, ...   \n",
       "860   [Flat, Mop, Set, የወለልና, የመስታወት, መወልወያ, ትልቁ, መጠ...   \n",
       "3507  [Serving, tray, ለዳቦ, ለእንጀራ, ለፈንዲሻ, እና, ሌሎች, ምግ...   \n",
       "3174  [GW, 3, in, 1, hot, air, Hair, styler, የሚዘንጡ, ...   \n",
       "\n",
       "                                                 labels  \n",
       "3867  [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  \n",
       "810   [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O...  \n",
       "2506                  [B-PRODUCT, I-PRODUCT, I-PRODUCT]  \n",
       "3653                             [B-PRODUCT, I-PRODUCT]  \n",
       "3468  [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  \n",
       "...                                                 ...  \n",
       "1130  [B-PRODUCT, I-PRODUCT, I-PRODUCT, O, O, O, O, ...  \n",
       "1294  [B-PRODUCT, I-PRODUCT, O, O, I-PRICE, O, O, O,...  \n",
       "860   [B-PRODUCT, I-PRODUCT, I-PRODUCT, O, O, O, O, ...  \n",
       "3507  [B-PRODUCT, I-PRODUCT, O, O, O, O, O, O, O, O,...  \n",
       "3174  [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  \n",
       "\n",
       "[3674 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Labeled_Message', 'cleaned_text', 'tokens_labels', 'tokens', 'labels', '__index_level_0__'],\n",
       "    num_rows: 409\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Labeled_Message', 'cleaned_text', 'tokens_labels', 'tokens', 'labels', '__index_level_0__'],\n",
       "    num_rows: 3674\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    # Tokenize the inputs\n",
    "    tokenized_inputs = tokenizer(examples['tokens'], padding='max_length', truncation=True, is_split_into_words=True)\n",
    "\n",
    "    # Initialize labels\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(i)  # Get word ids corresponding to the tokens\n",
    "        label_ids = [-100] * len(tokenized_inputs['input_ids'])  # Default to -100 (ignore index)\n",
    "\n",
    "        for word_idx in set(word_ids):\n",
    "            if word_idx is None: \n",
    "                continue  # Skip special tokens\n",
    "            # Use the label for the first token of the word\n",
    "            label_ids[word_ids.index(word_idx)] = label[word_idx]\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs['labels'] = labels\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 14041/14041 [00:16<00:00, 856.57 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply the tokenization and label alignment\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtokenized_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mcolumn_names)  \u001b[38;5;66;03m# This should show 'input_ids', 'attention_mask', and 'labels'\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenized_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset.column_names)  # This should show 'input_ids', 'attention_mask', and 'labels'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Step 7: Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # Output directory for model predictions and checkpoints\n",
    "    evaluation_strategy=\"epoch\",  # Evaluation strategy to adopt during training\n",
    "    save_strategy=\"epoch\",  # Save strategy to adopt during training\n",
    "    learning_rate=2e-5,  # Learning rate for optimization\n",
    "    per_device_train_batch_size=16,  # Batch size for training\n",
    "    per_device_eval_batch_size=16,  # Batch size for evaluation\n",
    "    num_train_epochs=3,  # Total number of training epochs\n",
    "    weight_decay=0.01,  # Strength of weight decay\n",
    "    save_total_limit=2,  # Limit the total amount of checkpoints\n",
    "    load_best_model_at_end=True,  # Load the best model when finished training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 8: Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,  # The instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,  # Training arguments, defined above\n",
    "    train_dataset=tokenized_dataset,  # Training dataset\n",
    "    eval_dataset=tokenized_dataset,  # Evaluation dataset\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2634 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 9: Fine-tune the model\n",
    "trainer.train()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
