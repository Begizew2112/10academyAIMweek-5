{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (4.45.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (3.0.1)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: filelock in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from datasets) (3.10.6)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from seqeval) (1.5.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from aiohttp->datasets) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yibabe\\desktop\\10academyaimweek-5\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16183 sha256=395af15d8c162761d604764ff877b97ffdcfd140ff9e92c063a492ee502af8a8\n",
      "  Stored in directory: c:\\users\\yibabe\\appdata\\local\\pip\\cache\\wheels\\5f\\b8\\73\\0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets seqeval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yibabe\\Desktop\\10academyAIMweek-5\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Yibabe\\Desktop\\10academyAIMweek-5\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Error while downloading from https://cdn-lfs.hf.co/xlm-roberta-base/6fd4797bc397c3b8b55d6bb5740366b57e6a3ce91c04c77f22aafc0c128e6feb?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1727892797&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNzg5Mjc5N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby94bG0tcm9iZXJ0YS1iYXNlLzZmZDQ3OTdiYzM5N2MzYjhiNTVkNmJiNTc0MDM2NmI1N2U2YTNjZTkxYzA0Yzc3ZjIyYWFmYzBjMTI4ZTZmZWI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=kkOe573GN4DwyR0LH-iBMPm7VC54uFxoZs64s1fup-itJzyGQUvCdzpuLxEFb%7EK-OQXteVMmgN6hcyDm6kJxAV%7E1qcA8FkKKOvICicnpcfuQETnywPD9ZTOgfLZ40VPTc0TxGOsYR8Nf6qHTY8Z7tarMMH%7E4xws2KmkczApWwDNAR2iUW45b1nRgCvNsI-dUYnV%7EimKfenCVCp%7EoIHbjL0cWbo6DHr6VixX%7Eu52JiRMlO%7EwrGnWJ5rNhZgjAOur4YVAwwDcEnzB3i5w2QQHFDWBZ8oN%7ESSTjSAPmj3RoeP2lO-bqaWVKPVdhkB-bj5Qsd%7EwR5JbDXA2O6tUxKw4Vmg__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "model_name = \"xlm-roberta-base\"  # You can also use bert-tiny-amharic if available\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=5)  # Adjust num_labels based on your entity types (e.g., products, prices, locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 983k/983k [00:00<00:00, 1.41MB/s]\n",
      "Generating train split: 100%|██████████| 14041/14041 [00:06<00:00, 2073.09 examples/s]\n",
      "Generating validation split: 100%|██████████| 3250/3250 [00:01<00:00, 2904.38 examples/s]\n",
      "Generating test split: 100%|██████████| 3453/3453 [00:01<00:00, 3179.55 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset with `trust_remote_code=True`\n",
    "dataset = load_dataset(\"conll2003\", split=\"train\", trust_remote_code=True)\n",
    "\n",
    "# Check the first few rows to ensure it's loaded correctly\n",
    "print(dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yibabe\\Desktop\\10academyAIMweek-5\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the XLM-Roberta tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the entire data from the CSV file\n",
    "data_file_path = r'C:\\Users\\Yibabe\\Desktop\\10academyAIMweek-5\\data\\cleaned_tokenized_and_labled_data.csv'  # Update this to the correct path of your CSV file\n",
    "df = pd.read_csv(data_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labeled_Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GW O\\nHAIR O\\nDRYER/Blower O\\nየፀጉር O\\nማድረቂያ O\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 B-PRODUCT\\nin I-PRODUCT\\n1 I-PRODUCT\\nPorcel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plastic B-PRODUCT\\nAnd I-PRODUCT\\nMetal I-PROD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Labeled_Message\n",
       "0  Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...\n",
       "1  Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...\n",
       "2  GW O\\nHAIR O\\nDRYER/Blower O\\nየፀጉር O\\nማድረቂያ O\\...\n",
       "3  2 B-PRODUCT\\nin I-PRODUCT\\n1 I-PRODUCT\\nPorcel...\n",
       "4  Plastic B-PRODUCT\\nAnd I-PRODUCT\\nMetal I-PROD..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming the relevant text column is named 'Labeled_Message'; adjust this if needed\n",
    "if 'Labeled_Message' not in df.columns:\n",
    "    raise ValueError(\"The 'Labeled_Message' column is not found in the DataFrame.\")\n",
    "\n",
    "# Redundant messages to be removed\n",
    "redundant_message = [\n",
    "    \"ከፍለው O\",\n",
    "    \"ካሉበት O\",\n",
    "    \"እንልካለን O\",\n",
    "    \"ክፍለሃገር O\",\n",
    "    \"ላላችሁ O\",\n",
    "    \"ደንበኞቻችን O\",\n",
    "    \"የፈለጉትን O\",\n",
    "    \"ዕቃ O\",\n",
    "    \"በመልዕክት O\",\n",
    "    \"እንልክልዎታለን O\",\n",
    "    \"ለማዘዝ O\",\n",
    "    \"@ordermertteka1 O\",\n",
    "    \"@ordermertteka2 O\",\n",
    "    \"ለወዳጅዎ O\",\n",
    "    \"forward O\",\n",
    "    \"በማድረግ O\",\n",
    "    \"ይተባበሩን O\",\n",
    "    \"0944-22-23-24 O\",\n",
    "    \"0904-94-48-48 O\",\n",
    "    \"አድራሻችን O\",\n",
    "    \"መገናኛ I-LOC\",\n",
    "    \"ዘፍመሽ O\",\n",
    "    \"ግራንድ O\",\n",
    "    \"ሞል O\",\n",
    "    \"3ኛ O\",\n",
    "    \"ፎቅ O\",\n",
    "    \"ከሊፍት O\",\n",
    "    \"ሲወርዱ O\",\n",
    "    \"ወደ O\",\n",
    "    \"ቀኝ O\",\n",
    "    \"ታጥፈው O\",\n",
    "    \"ቀጥታ O\",\n",
    "    \"376 I-LOC\",\n",
    "    \"በኪስዎ O\",\n",
    "    \"ጥሬ O\",\n",
    "    \"ገንዘብ O\",\n",
    "    \"ካልያዙ O\",\n",
    "    \"በሞባይል O\",\n",
    "    \"ማስተላለፍ O\",\n",
    "    \"ይችላሉ። O\",\n",
    "    \"ይሄንን O\",\n",
    "    \"t.me/MerttEka O\",\n",
    "    \"ተጭነው O\",\n",
    "    \"join O\",\n",
    "    \"ያድርጉ፣ O\",\n",
    "    \"ቤተሰብ O\",\n",
    "    \"ይሁኑ O\"\n",
    "]\n",
    "\n",
    "# Function to clean redundant messages\n",
    "def clean_redundant_messages(text):\n",
    "    # Check if the text is a string\n",
    "    if isinstance(text, str):\n",
    "        for message in set(redundant_message):\n",
    "            text = text.replace(message + \"\\n\", \"\")\n",
    "        return text.strip()  # Remove leading/trailing whitespace after replacement\n",
    "    return None  # Return None for non-string entries\n",
    "\n",
    "# Clean the redundant messages in the DataFrame\n",
    "df['cleaned_text'] = df['Labeled_Message'].apply(clean_redundant_messages)\n",
    "\n",
    "# Function to split tokens and labels\n",
    "def split_tokens_and_labels(text):\n",
    "    if isinstance(text, str):  # Ensure the input is a string\n",
    "        lines = text.strip().split('\\n')\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for line in lines:\n",
    "            if line.strip():  # Ensure the line is not empty\n",
    "                token, label = line.rsplit(' ', 1)\n",
    "                tokens.append(token)\n",
    "                labels.append(label)\n",
    "        return tokens, labels\n",
    "    else:\n",
    "        return [], []  # Return empty lists for non-string entries\n",
    "\n",
    "# Apply the token splitting\n",
    "df['tokens_labels'] = df['cleaned_text'].apply(split_tokens_and_labels)\n",
    "\n",
    "# Separate tokens and labels into two new columns\n",
    "df['tokens'] = df['tokens_labels'].apply(lambda x: x[0])\n",
    "df['labels'] = df['tokens_labels'].apply(lambda x: x[1])\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "output_file_path = r'C:\\Users\\Yibabe\\Desktop\\10academyAIMweek-5\\data\\cleaned_data.csv' # Update this to your desired output path\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...</td>\n",
       "      <td>[Car, Aromatherapy, Solar, Vortex, ይሁኑ]</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...</td>\n",
       "      <td>[Car, Aromatherapy, Solar, Vortex, የመኪና, መዓዛ, ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GW O\\nHAIR O\\nDRYER/Blower O\\nየፀጉር O\\nማድረቂያ O\\...</td>\n",
       "      <td>[GW, HAIR, DRYER/Blower, የፀጉር, ማድረቂያ, ፎን, 6000...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 B-PRODUCT\\nin I-PRODUCT\\n1 I-PRODUCT\\nPorcel...</td>\n",
       "      <td>[2, in, 1, Porcelain, Dessert, Bowel, የሰላጣ, እና...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plastic B-PRODUCT\\nAnd I-PRODUCT\\nMetal I-PROD...</td>\n",
       "      <td>[Plastic, And, Metal, Cubic, Cloth, Cabinet, ዘ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>2500 B-PRODUCT</td>\n",
       "      <td>[2500]</td>\n",
       "      <td>[B-PRODUCT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>ዋጋ B-PRODUCT\\n2500 I-PRODUCT\\n0983063957 O</td>\n",
       "      <td>[ዋጋ, 2500, 0983063957]</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>የሙያ B-PRODUCT\\nባለቤት I-PRODUCT\\nመሆን I-PRODUCT\\n...</td>\n",
       "      <td>[የሙያ, ባለቤት, መሆን, መሠልጠን, ነው።, ቀለም, ቀቢ, ሳያስፈልግዎ,...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>ቤትና B-PRODUCT\\nግቢዎን I-PRODUCT\\nእንዲሁም I-PRODUCT...</td>\n",
       "      <td>[ቤትና, ግቢዎን, እንዲሁም, የብረት, እና, የእንጨት, ቁሳቁስዎን, ቀለ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>ለማዘዝ B-PRODUCT\\nhttps://t.megojomewechiyaeka O</td>\n",
       "      <td>[ለማዘዝ, https://t.megojomewechiyaeka]</td>\n",
       "      <td>[B-PRODUCT, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4083 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_text  \\\n",
       "0     Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...   \n",
       "1     Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...   \n",
       "2     GW O\\nHAIR O\\nDRYER/Blower O\\nየፀጉር O\\nማድረቂያ O\\...   \n",
       "3     2 B-PRODUCT\\nin I-PRODUCT\\n1 I-PRODUCT\\nPorcel...   \n",
       "4     Plastic B-PRODUCT\\nAnd I-PRODUCT\\nMetal I-PROD...   \n",
       "...                                                 ...   \n",
       "4078                                     2500 B-PRODUCT   \n",
       "4079         ዋጋ B-PRODUCT\\n2500 I-PRODUCT\\n0983063957 O   \n",
       "4080  የሙያ B-PRODUCT\\nባለቤት I-PRODUCT\\nመሆን I-PRODUCT\\n...   \n",
       "4081  ቤትና B-PRODUCT\\nግቢዎን I-PRODUCT\\nእንዲሁም I-PRODUCT...   \n",
       "4082     ለማዘዝ B-PRODUCT\\nhttps://t.megojomewechiyaeka O   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0               [Car, Aromatherapy, Solar, Vortex, ይሁኑ]   \n",
       "1     [Car, Aromatherapy, Solar, Vortex, የመኪና, መዓዛ, ...   \n",
       "2     [GW, HAIR, DRYER/Blower, የፀጉር, ማድረቂያ, ፎን, 6000...   \n",
       "3     [2, in, 1, Porcelain, Dessert, Bowel, የሰላጣ, እና...   \n",
       "4     [Plastic, And, Metal, Cubic, Cloth, Cabinet, ዘ...   \n",
       "...                                                 ...   \n",
       "4078                                             [2500]   \n",
       "4079                             [ዋጋ, 2500, 0983063957]   \n",
       "4080  [የሙያ, ባለቤት, መሆን, መሠልጠን, ነው።, ቀለም, ቀቢ, ሳያስፈልግዎ,...   \n",
       "4081  [ቤትና, ግቢዎን, እንዲሁም, የብረት, እና, የእንጨት, ቁሳቁስዎን, ቀለ...   \n",
       "4082               [ለማዘዝ, https://t.megojomewechiyaeka]   \n",
       "\n",
       "                                                 labels  \n",
       "0       [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O]  \n",
       "1     [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O...  \n",
       "2     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3     [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  \n",
       "4     [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  \n",
       "...                                                 ...  \n",
       "4078                                        [B-PRODUCT]  \n",
       "4079                          [B-PRODUCT, I-PRODUCT, O]  \n",
       "4080  [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  \n",
       "4081  [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  \n",
       "4082                                     [B-PRODUCT, O]  \n",
       "\n",
       "[4083 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the resulting DataFrame (optional)\n",
    "df[['cleaned_text', 'tokens', 'labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to split cleaned text into tokens and labels\n",
    "def split_tokens_labels(row):\n",
    "    cleaned_text = row['cleaned_text']\n",
    "    \n",
    "    # Check if cleaned_text is None or an empty string\n",
    "    if cleaned_text is None or cleaned_text.strip() == \"\":\n",
    "        return ([], []), [], []  # Return empty lists if cleaned_text is not valid\n",
    "    \n",
    "    # Split the cleaned text into lines\n",
    "    lines = cleaned_text.strip().split('\\n')\n",
    "    \n",
    "    # Initialize lists for tokens and labels\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate through each line\n",
    "    for line in lines:\n",
    "        # Split each line by space\n",
    "        parts = line.rsplit(' ', 1)  # Split only at the last space\n",
    "        if len(parts) == 2:  # Ensure there's a token and a label\n",
    "            token, label = parts\n",
    "            tokens.append(token)\n",
    "            labels.append(label)\n",
    "    \n",
    "    # Create tokens_labels format as a tuple of lists\n",
    "    tokens_labels = (tokens, labels)\n",
    "    \n",
    "    return tokens_labels, tokens, labels\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df[['tokens_labels', 'tokens', 'labels']] = df.apply(split_tokens_labels, axis=1, result_type='expand')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens_labels</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...</td>\n",
       "      <td>([Car, Aromatherapy, Solar, Vortex, ይሁኑ], [B-P...</td>\n",
       "      <td>[Car, Aromatherapy, Solar, Vortex, ይሁኑ]</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...</td>\n",
       "      <td>([Car, Aromatherapy, Solar, Vortex, የመኪና, መዓዛ,...</td>\n",
       "      <td>[Car, Aromatherapy, Solar, Vortex, የመኪና, መዓዛ, ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GW O\\nHAIR O\\nDRYER/Blower O\\nየፀጉር O\\nማድረቂያ O\\...</td>\n",
       "      <td>([GW, HAIR, DRYER/Blower, የፀጉር, ማድረቂያ, ፎን, 600...</td>\n",
       "      <td>[GW, HAIR, DRYER/Blower, የፀጉር, ማድረቂያ, ፎን, 6000...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 B-PRODUCT\\nin I-PRODUCT\\n1 I-PRODUCT\\nPorcel...</td>\n",
       "      <td>([2, in, 1, Porcelain, Dessert, Bowel, የሰላጣ, እ...</td>\n",
       "      <td>[2, in, 1, Porcelain, Dessert, Bowel, የሰላጣ, እና...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plastic B-PRODUCT\\nAnd I-PRODUCT\\nMetal I-PROD...</td>\n",
       "      <td>([Plastic, And, Metal, Cubic, Cloth, Cabinet, ...</td>\n",
       "      <td>[Plastic, And, Metal, Cubic, Cloth, Cabinet, ዘ...</td>\n",
       "      <td>[B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text  \\\n",
       "0  Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...   \n",
       "1  Car B-PRODUCT\\nAromatherapy I-PRODUCT\\nSolar I...   \n",
       "2  GW O\\nHAIR O\\nDRYER/Blower O\\nየፀጉር O\\nማድረቂያ O\\...   \n",
       "3  2 B-PRODUCT\\nin I-PRODUCT\\n1 I-PRODUCT\\nPorcel...   \n",
       "4  Plastic B-PRODUCT\\nAnd I-PRODUCT\\nMetal I-PROD...   \n",
       "\n",
       "                                       tokens_labels  \\\n",
       "0  ([Car, Aromatherapy, Solar, Vortex, ይሁኑ], [B-P...   \n",
       "1  ([Car, Aromatherapy, Solar, Vortex, የመኪና, መዓዛ,...   \n",
       "2  ([GW, HAIR, DRYER/Blower, የፀጉር, ማድረቂያ, ፎን, 600...   \n",
       "3  ([2, in, 1, Porcelain, Dessert, Bowel, የሰላጣ, እ...   \n",
       "4  ([Plastic, And, Metal, Cubic, Cloth, Cabinet, ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0            [Car, Aromatherapy, Solar, Vortex, ይሁኑ]   \n",
       "1  [Car, Aromatherapy, Solar, Vortex, የመኪና, መዓዛ, ...   \n",
       "2  [GW, HAIR, DRYER/Blower, የፀጉር, ማድረቂያ, ፎን, 6000...   \n",
       "3  [2, in, 1, Porcelain, Dessert, Bowel, የሰላጣ, እና...   \n",
       "4  [Plastic, And, Metal, Cubic, Cloth, Cabinet, ዘ...   \n",
       "\n",
       "                                              labels  \n",
       "0    [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O]  \n",
       "1  [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, O...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  \n",
       "4  [B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT, I...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Display the updated DataFrame\n",
    "df[['cleaned_text', 'tokens_labels', 'tokens', 'labels']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset for training\n",
    "train_data = [(row['tokens'], row['labels']) for _, row in df.iterrows() if row['tokens'] and row['labels']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'O': 82396, 'I-PRODUCT': 14789, 'I-PRICE': 11316, 'B-PRODUCT': 4066, 'I-LOC': 2140, 'o': 1, 'price': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Flatten labels from the train_data\n",
    "all_labels = [label for _, labels in train_data for label in labels]\n",
    "label_counts = Counter(all_labels)\n",
    "\n",
    "print(label_counts)  # Display the counts of each label\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
